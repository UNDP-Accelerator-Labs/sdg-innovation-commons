# Sensemaking of the CPD

[[focal_point:javier.brolo@undp.org]]

[[year:2022]]

[[type:experiment]]

[[datasources:observation]]
[[datasources:interviews]]
[[methods:Sensemaking]]
[[sdgs:1. No poverty]]
[[sdgs:16. Peace, justice and strong institutions]]
[[sdgs:17. Partnerships for the goals]]
[[thematic_areas:digitalization]]
[[thematic_areas:knowledge management]]
[[country:Guatemala]]
[[latlng:15.696016409029419,-90.36015683588494]]
[[assignment_type:non-random assignment]]
[[control_group:Yes, the same group but before the intervention]]
[[experiment_status:Completed]]
[[experiment_type:Pre Experimental (trial and error, prototype, a/b testing)]]
[[partnering_sector:United Nations agency]]
[[quality_check:The hypothesis is clearly stated]]
[[quality_check:This activity has a low risk]]
[[quality_check:This activity is relevant to a CPD outcome]]
[[quality_check:This activity offers a high potential for scaling]]
[[quality_check:This activity offers strong collaboration oportunities]]
[[sample_size:1]]
[[scaling:led to adoption of new ways of working by our partners]]
[[scaling:led to partnerships]]
[[total_cost:Less than 1,000 USD]]
## Overview
**This section is to explain the basics of the activity**

> Prepared by (Name of the experimenter)

Javier Brolo and María Inés Castañeda



> On date (Day/Month/Year)

June 18th, 2021



> Current status of experimental activity

> What portfolio does this activity correspond to? If any

Knowledge management



> What is the frontier challenge does this activity responds to?

How to base decisions and behaviors on existing knowledge



> What is the learning question(from your action learning plan) is this activity related to?

What makes it easier for decisions and behaviors to be informed by existing knowledge?



> Please categorize the type that best identifies this experimental activity:

- Pre Experimental (trial and error, prototype, a/b testing)

> Which sector are you partnering with for this activity? Please select all that apply

- United Nations agency

> Please list the names of partners mentioned in the previous question:

Country office programmatic areas, with a close relation to the Unit of Strategic Support


## Design
**Explain the design of the experimental activity. In general, experimental activities consist on trying to learn how results are connected to a stimuli.**

> What is the specific learning intent of the activity?

We wanted to learn if the information contained in the CPD

can be analyzed to identify patterns that reveal a distinctive

"style" of UNDP interventions. This way, it would be possible to

break silos, making it more explicitly how the different projects within the

country office complement each other, and how capacities across the office can

be leveraged. 



> What is your hypothesis? IF... THEN....

If we use sensemaking to analyze the CPD, then we will be easier to identify a shared understanding of UNDP's approach to development, which is needed to break silos and leverage capacities across the office's projects. 



> Does the activity use a control group for comparison?

- Yes, the same group but before the intervention

> How is the intervention assigned to different groups in your experiment?

- non-random assignment

> Describe which actions will you take to test your hypothesis:

For this experiment we conducted

an inductive analysis of the CPD through four steps. First, we read the CPD in

detail, to identify cause and effect relationships implicitly stated. Then, we

grouped the cause-and-effect relationships according to similarities perceived

along different lines. Then the emergent patterns were identified and labeled.

Lastly, an abstract version of the CPD was proposed that described the causal

links addressed by UNDP interventions.



> What is the unit of analysis of this experimental activity?

The CPD 



> Please describe the data collection technique proposed

Data was collected through observation, as well as through individual and group interviews during the validation processes of the sensemaking exercise. 



> What is the timeline of the experimental activity? (Months/Days)

One month



> What is the estimated sample size?

- 1

> What is the total estimated monetary resources needed for this experiment?

> Quality Check

- This activity is relevant to a CPD outcome
- The hypothesis is clearly stated
- This activity offers strong collaboration oportunities
- This activity offers a high potential for scaling
- This activity has a low risk

> Please upload any supporting images or visuals for this experiment.


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/3c9382326e1b6201a507a922e66f1723.png)


> What are the estimated non- monetary resources required for this experiment? (time allocation from team, external resources, etc) If any.

We needed access to mural, a computer, and time. 


## Results
**Only complete this section when presenting results**

> Was the original hypothesis (If.. then) proven or disproven?

Partially proven. We were able to successfully make sense of the CPD contents and underlying patterns of casual relations in the interventions that can be modeled. 



> Do you have observations about the methodology chosen for the experiment? What would you change?

Ideally, we would conduct focus

groups in which we randomly assign versions of the CPD and measure variations

in the opportunities identify to work across silos and leverage capacities

across teams. But the opportunities to control the situation are low, and CPDs

don't occur often. Also, program officers and project coordinators are scarce

and with limited time. Therefore, a possibility for testing is through

progressive iterations of the exercise for the time being.



> From design to results, how long did this activity take? (Time in months)

About a month



> What were the actual monetary resources invested in this activity? (Amount in USD)

US$0.00



> Does this activity have a follow up or a next stage? Please explain

We are identifying opportunities to validate the framework when designing new projects. 



> Is this experiment planned to scale? How? With whom?

We want to scale the use of the framework to make the design of project proposals more agile. 



> Please include any supporting images that could be used to showcase this activity


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/8c299baaafa356c448c7efa9889f3ac3.png)


> Considering the outcomes of this experimental activity, which of the following best describe what happened after? (Please select all that apply)

- This experiment led to partnerships
- This experiment led to adoption of new ways of working by our partners
## Learning
**This section is aimed at presenting the learning outcomes from this activity. **

> What do you know now about the action plan learning question that you did not know before? What were your main learnings during this experiment?

We learn that sensemaking can be an effective way to structure information and make it easier to remember. We learned that even though UNDP approach to development may seem differently from project to project, there are underlying patterns of casual relations in the interventions that can be modeled. However, we also learned that abstract frameworks are not as easily grasped, and development practitioners tend to privilege topics rather than methodologies or processes. In any case, the pattern of UNDP approach to development identified has three components: strengthening people, strengthening internal capacity of institutions, strengthening institutional coordination, and working with implementing partners. 



> What were the main obstacles and challenges you encountered during this activity?

It was very time consuming, and we realized that there is no single way to organize the information to make sense of it. Making sense of information in a way is like a painting, a representation, which can be done in different ways and it's hard to tell which representations are better than others. 



> Who at UNDP might benefit from the results of this experimental activity? Why?

Representation and programmatic areas of the UNDP country office. Also, it may benefit counterparts to understand UNDP as having a unified approach to development to organize their requests in a more effective way. 



> Who outside UNDP might benefit from the results of this experiment? and why?

Counterparts will benefit from

the increased capacity of UNDP to design project proposals. Also, they will

benefit from understanding this framework to make their requests more

effective. 



> Did this experiment require iterations? If so, how many and what did you change/adjust along the way? and why?

There was iterative process in the steps to identify patterns and label groupings. Also, there was an iterative process in the way to present the results and validate them.



> What advice would you give someone wanting to replicate this experimental activity?

Laying out steps in the process of sensemaking before organizing the information can help scale and collaborate on the amount of information that can be processed more quickly. 



> Can this experiment be replicated in another thematic area or other SDGs? If yes, what would need to be considered, if no, why not?

Yes, we can scale the process of sensemaking to the interventions in more specific SDGs



> How much the "sense" and "explore" phases of the learning cycle influenced/shaped this experiment? In hindsight, what would you have done differently with your fellow Solution Mapper and Explorer?

To a lesser extent. 



> What surprised you?

It was surprising that the results of the sensemaking exercise were able to accommodate the partial components each project focuses on. However, it is also surprising that it's not trivial which level of abstraction are the patterns identified, and that the expected balance of specificity and generality is not homogeneous across the components of the framework. 



# Text mining the Performance Evaluation System

[[focal_point:luis.cervantes@undp.org]]

[[year:2022]]

[[type:experiment]]

[[sdgs:16. Peace, justice and strong institutions]]
[[country:Mexico]]
[[latlng:23.949171200328962,-102.53030787352746]]
[[assignment_type:other]]
[[control_group:It does not use a control group]]
[[quality_check:The hypothesis is clearly stated]]
[[quality_check:This activity has a low risk]]
[[quality_check:This activity offers a high potential for scaling]]
[[quality_check:This activity offers strong collaboration oportunities]]
[[sample_size:More than 1,000]]
[[total_cost:Between 1,000 and 9,999 USD]]
## Overview
**This section is to explain the basics of the activity**

> Name of the experimental activity

> Prepared by (Name of the experimenter)

> On date (Day/Month/Year)

> Current status of experimental activity

> What portfolio does this activity correspond to? If any

> What is the frontier challenge does this activity responds to?

> What is the learning question(from your action learning plan) is this activity related to?

> Please categorize the type that best identifies this experimental activity:

- 

> Which sector are you partnering with for this activity? Please select all that apply

- 

> Please list the names of partners mentioned in the previous question:
## Design
**Explain the design of the experimental activity. In general, experimental activities consist on trying to learn how results are connected to a stimuli.**

> What is the specific learning intent of the activity?

This is an experiment in collective intelligence. We use text mining techniques in the Performance Evaluation System to collectively assimilate the main lessons learned by the people on the front lines of public program implementation. One of the elements of Results-Based Budgeting in Mexico's Public Administration implies that the people in charge of operating any budgetary program define specific performance objectives and targets and capture them in matrices and results indicator sheets. These tools are the result of the application of the Logical Framework Methodology. They serve to establish a causal relationship between the activities carried out by the programs and their purpose, as well as their contribution to a higher goal that the policy seeks to achieve, and are the basis for the follow-up and monitoring of program performance in the Performance Evaluation System.  In addition to containing data on the progress of indicators and the status of compliance with targets, individuals can add contextual information. For each indicator and budget cycle, responsible parties include a justification paragraph that describes, to their knowledge, the reasons for the difference between the indicator's progress and the target. These text records contain valuable information on the lessons learned by those on the front line of program implementation and the challenges they face in implementation. But, because of the difficulty involved in aggregating and systematizing them, they are hardly used to identify patterns beyond the individual program level.  This experiment is the first exercise to make sense of and find patterns in an aggregate way about what people mention in the texts justifying the differences between progress and goals. These texts have the potential to shed light on the factors behind the failure of some budget programs to meet their targets. All the information used to conduct this exercise is found in the Performance Evaluation System's indicator progress database from 2013 to 2019, which is available on the Budget Transparency portal and contains records of the progress of 97,515 indicators. The justification texts are available thanks to the work of thousands of people who work in the public service and are an important repository of learning about what it means to operate public policies. 

> What is your hypothesis? IF... THEN....

If we can find patterns and trends in the text entries made by public officials in the performance evaluation system, where they justify why their programs fail to achieve the goals they set out to achieve, then we can elevate those patterns as learnings of a collective intelligence so that decision-makers and citizens know where efforts should be concentrated to improve the performance of public institutions.

> Does the activity use a control group for comparison?

- No, it does not use a control group

> How is the intervention assigned to different groups in your experiment?

- other

> Describe which actions will you take to test your hypothesis:

Two text mining algorithms were designed to translate the textual information and be able to take advantage of it in a quantitative way. The first is an algorithm capable of ordering the texts according to their linguistic complexity in order to distinguish between those that are easy to read and those that are more sophisticated. The second is an algorithm capable of evaluating the similarity of each of the texts with each of the nine causes predefined by the Performance Evaluation Unit of the Ministry of Finance and Public Credit. These causes are contained in the GUIDE FOR REPORTING FINAL PROGRESS AGAINST COMMITTED GOALS IN PERFORMANCE INDICATORS that is sent to the agencies for guidance purposes.  Translated with www.DeepL.com/Translator (free version)

> What is the unit of analysis of this experimental activity?

Individual text registries entered by public officials in their role as public spending responsible parties 

> Please describe the data collection technique proposed

Administrative records

> What is the timeline of the experimental activity? (Months/Days)

6 months

> What is the estimated sample size?

- More than 1,000

> What is the total estimated monetary resources needed for this experiment?

> Quality Check

- The hypothesis is clearly stated
- This activity offers strong collaboration oportunities
- This activity offers a high potential for scaling
- This activity has a low risk

> Please upload any supporting images or visuals for this experiment.


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/3eaebb7d93e5fe06a6e398ae9be5829d.png)


> Please upload any supporting links
[https://www.mx.undp.org/content/mexico/es/home/blog/20210/12/how-text-mining-can-help-us-learn-about-public-spending-performa.html](https://www.mx.undp.org/content/mexico/es/home/blog/20210/12/how-text-mining-can-help-us-learn-about-public-spending-performa.html)

> What are the estimated non- monetary resources required for this experiment? (time allocation from team, external resources, etc) If any.

Apart from hiring a consultant. We spent 3 months of weekly 1 hr meetings between the Head of Experimentation, the consultant (programmer) and a team of 3 public servants from the Ministry of Finance.  
## Results
**Only complete this section when presenting results**

> Was the original hypothesis (If.. then) proven or disproven?

It was proven that patterns and trends in the text entries made by public officials in the performance evaluation system can in fact be found and can be elevated as learnings of a collective intelligence so that decision-makers and citizens know where efforts should be concentrated to improve the performance of public institutions.

> Do you have observations about the methodology chosen for the experiment? What would you change?

Formalize the collaboration in the form of an MoU. The engagement of our conterpart, the Ministry of Finance, relied heavily in genuine curiosity and willingness to know the results, but it was not formalized by an MoU or anything as such. Now that we're willing to publish the results in the form of a report the person in charge of the Performance Evaluation Unit in the Ministry no longer works there so we need to start again building the relationship. 

> From design to results, how long did this activity take? (Time in months)

8 months

> What were the actual monetary resources invested in this activity? (Amount in USD)

Around 7,000 USD

> Does this activity have a follow up or a next stage? Please explain

Yes, we're looking to present the results to the new team in charge of the Performance Evaluation Unit, and convince the Ministry to finance a Development Cooperation Project (PRODOC) with UNDP Mexico CO. Specifically aimed at human centered and collective intelligence based innovation in the Performance Evaluation System, using this as an example of the broad ways in which the system can be transformed in order to be more relevant.

> Is this experiment planned to scale? How? With whom?

Yes, with the Ministry of Finance

> Please include any supporting images that could be used to showcase this activity


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/1b7f95c9e0ea31fea7b983ca6a771e8b.png)


> Please add any supporting links that describe the planning, implementation, results of learning of this activity? For example a tweet, a blog, or a report. 
[https://www.mx.undp.org/content/mexico/es/home/blog/20210/12/a-lab-experiment-that-can-help-identify-and-address-potential-ga.html](https://www.mx.undp.org/content/mexico/es/home/blog/20210/12/a-lab-experiment-that-can-help-identify-and-address-potential-ga.html)
## Learning
**This section is aimed at presenting the learning outcomes from this activity. **

> What do you know now about the action plan learning question that you did not know before? What were your main learnings during this experiment?

It takes time to find the sweet spot. Our main learning was that continuous communication with our conterparts is necessary to identify learning gaps.   

> What were the main obstacles and challenges you encountered during this activity?

We lack agile administrative procedures that could allow us to react quickly. Once we identified the sweet spot it took months to hire a programmer who could help us do the experiment. 

> Who at UNDP might benefit from the results of this experimental activity? Why?

Whoever is in charge of the performance monitoring at a grand scale. Since this experiment was helpful to analyze thousand of records pertaining to single development projects and create aggregated collective intelligence.  

> Who outside UNDP might benefit from the results of this experiment? and why?

Government ministries in charge of Performance Evaluation Systems and Results Based Budgeting.

> Did this experiment require iterations? If so, how many and what did you change/adjust along the way? and why?

Yes, at least 3 iterations that helped us adjust the scope of the Learning Cycle 

> What advice would you give someone wanting to replicate this experimental activity?

You can find the whole programming script here: https://github.com/acclab-mx/textmining_pnud

> Can this experiment be replicated in another thematic area or other SDGs? If yes, what would need to be considered, if no, why not?

Yes

> How much the "sense" and "explore" phases of the learning cycle influenced/shaped this experiment? In hindsight, what would you have done differently with your fellow Solution Mapper and Explorer?

It took a lot of effort from all of us to identify the sweet spot

> What surprised you?

The results are quite surprising and we hope the can become viral.

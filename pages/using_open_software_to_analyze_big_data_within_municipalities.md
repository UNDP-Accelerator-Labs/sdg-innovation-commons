# Using open software to analyze big-data within municipalities

[[focal_point:javier.brolo@undp.org]]

[[year:2022]]

[[type:experiment]]

[[datasources:Open data]]
[[methods:Data Visualisation]]
[[sdgs:11. Sustainable cities and communities]]
[[sdgs:13. Climate action]]
[[sdgs:17. Partnerships for the goals]]
[[thematic_areas:big data analysis]]
[[thematic_areas:waste management]]
[[thematic_areas:open software]]
[[country:Guatemala]]
[[latlng:15.696016409029419,-90.36015683588494]]
[[assignment_type:other]]
[[control_group:It does not use a control group]]
[[experiment_status:Completed]]
[[experiment_type:Pre Experimental (trial and error, prototype, a/b testing)]]
[[experiment_type:Quasi Experimental (Analytical, observations, etc)]]
[[partnering_sector:Private Sector]]
[[partnering_sector:Public Sector]]
[[partnering_sector:United Nations agency]]
[[quality_check:The hypothesis is clearly stated]]
[[quality_check:This activity has a low risk]]
[[quality_check:This activity is relevant to a CPD outcome]]
[[quality_check:This activity offers a high potential for scaling]]
[[quality_check:This activity offers strong collaboration oportunities]]
[[sample_size:More than 1,000]]
[[scaling:did not scale yet]]
[[total_cost:Less than 1,000 USD]]
## Overview
**This section is to explain the basics of the activity**

> Prepared by (Name of the experimenter)

Javier Brolo and Juan Pablo Rustrián 



> On date (Day/Month/Year)

August 31th, 2022



> Current status of experimental activity

> What portfolio does this activity correspond to? If any

Co-creation of waste management solutions



> What is the frontier challenge does this activity responds to?

How to improve the collaboration between society and public institutions to increase resilience to climate change



> What is the learning question(from your action learning plan) is this activity related to?

How to improve waste management



> Please categorize the type that best identifies this experimental activity:

- Pre Experimental (trial and error, prototype, a/b testing)
- Quasi Experimental (Analytical, observations, etc)

> Which sector are you partnering with for this activity? Please select all that apply

- United Nations agency
- Public Sector
- Private Sector

> Please list the names of partners mentioned in the previous question:

The environmental programmatic

unit from the UNDP Office, Local Governments, Municipalities, The Ministry of

Environment and Natural Resources


## Design
**Explain the design of the experimental activity. In general, experimental activities consist on trying to learn how results are connected to a stimuli.**

> What is the specific learning intent of the activity?

We wanted to learn if using an

open software is a viable method to analyze big population data. Analyzing big

population data could help make better public policies adapted to their beneficiaries,

in this case it would help to learn if there are differences within access to a

public service for difference groups and help to extend its cover. 



> What is your hypothesis? IF... THEN....

If we use open software to analyze big population data, then we will be able to overcome limitations of aggregated data and measure differences by group within municipalities.



> Does the activity use a control group for comparison?

- No, it does not use a control group

> How is the intervention assigned to different groups in your experiment?

- other

> Describe which actions will you take to test your hypothesis:

First, the data is combined by focusing on people. This implies that in each row of the database, the characteristics of a person in the census are included (based on the XII National Population Census and VII of Household from 2018), and the characteristics of the home and dwelling are added, repeating it for each person who lives there. Second, the variables of interest are created and recompressed at the municipality level. From the combined database created in the previous step, it is possible to create variables that allow a more detailed analysis of each municipality. Finally, the results are analyzed at the intra-municipality level and from this process on, it's possible to offer greater light on access to a public service (in this case, access to waste collection service). 



> What is the unit of analysis of this experimental activity?

People registered in the census (with or without access to a public service).



> Please describe the data collection technique proposed

Secondary data sources collected from open data sources provided by official national institutions. 



> What is the timeline of the experimental activity? (Months/Days)

1 week



> What is the estimated sample size?

- More than 1,000

> What is the total estimated monetary resources needed for this experiment?

> Quality Check

- This activity is relevant to a CPD outcome
- The hypothesis is clearly stated
- This activity offers strong collaboration oportunities
- This activity offers a high potential for scaling
- This activity has a low risk

> Please upload any supporting images or visuals for this experiment.


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/17bfdb2e8fe261f68c2f92646bb42f9b.png)


> What are the estimated non- monetary resources required for this experiment? (time allocation from team, external resources, etc) If any.

We need access to data, software for analysis, and skills to analyze big data. 


## Results
**Only complete this section when presenting results**

> Was the original hypothesis (If.. then) proven or disproven?

Proven. The use of open software allowed us to analyze big population data. Now we will be able to overcome limitations of aggregated data and measure differences by group within municipalities, in this case overcome limitations could help to extend the coverage of a public service in municipalities (population) who don´t have current access (waste collection service or education access)



> Do you have observations about the methodology chosen for the experiment? What would you change?

Using big data possess challenges

and requires a considerable amount of knowledge on how to analyze different

types of data. In addition, it'd interesting to work it with other

municipalities in the same department, this would allow us to understand more

how helpful the use of open software is to overcome limitations of aggregated

data. 



> From design to results, how long did this activity take? (Time in months)

Less than a week



> What were the actual monetary resources invested in this activity? (Amount in USD)

US$0.00



> Does this activity have a follow up or a next stage? Please explain

Used wisely, and aware of its limitations, the data reduce uncertainty and offer a common point of reference to those who make decisions on public policy for development.



> Is this experiment planned to scale? How? With whom?

No.



> Please include any supporting images that could be used to showcase this activity


![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/648130998ee8bf922a32296ca9a57912.png)

![Missing alt text](https://undp-accelerator-labs.github.io/Archive_SDG_Commons_2022/blobs/experiments/0b1d016f1b7746c0dbeb61fe7146fb4e.png)


> Considering the outcomes of this experimental activity, which of the following best describe what happened after? (Please select all that apply)

- This experiment did not scale yet
## Learning
**This section is aimed at presenting the learning outcomes from this activity. **

> What do you know now about the action plan learning question that you did not know before? What were your main learnings during this experiment?

Mass data can be messy and does not allow more specific information to be identified, in this case access to a public service by a group of specific people. With the use of open software, we learned to identify this information from the disaggregation of the data.



> What were the main obstacles and challenges you encountered during this activity?

The main obstacles were the skills needed to process and integrate the data from each sources.



> Who at UNDP might benefit from the results of this experimental activity? Why?

All UNDP projects could benefit from incorporating open software in their repertoire of methods to analyze big data. 



> Who outside UNDP might benefit from the results of this experiment? and why?

Local governments or those who oversee improving public policies. 



> Did this experiment require iterations? If so, how many and what did you change/adjust along the way? and why?

Yes, we needed to run the code many times to make it clean and reproducible. 



> What advice would you give someone wanting to replicate this experimental activity?

We would recommend having access to an open software (friendly one) and try to work with a big data base in a national context, if it is possible to learn a little context of the problem you want to analyze to have the right understanding. 



> Can this experiment be replicated in another thematic area or other SDGs? If yes, what would need to be considered, if no, why not?

Absolutely. We could use open software to disaggregate data and focus on topics other than public policies. The idea is to learn how to work with open, big, and messy data. 



> How much the "sense" and "explore" phases of the learning cycle influenced/shaped this experiment? In hindsight, what would you have done differently with your fellow Solution Mapper and Explorer?

Sense and explore have been involved in defining the topic area of interest. The results will be especially useful for data analysis that will be conducted by exploration. 



> What surprised you?

What is surprising is knowing the potential of large data sets at a national level, knowing that the available data is generally useful but if we work with the correct analysis tools we can get a higher potential, and use it to improve guided decision making to public policies.



# Evaluating Crowdsourcing Behaviours in Identifying Online Misinformation

[[type:publications]]

[[source:https://www.undp.org/kenya/publications/evaluating-crowdsourcing-behaviours-identifying-online-misinformation]]

[Original article published here](https://www.undp.org/kenya/publications/evaluating-crowdsourcing-behaviours-identifying-online-misinformation)


[[year:2022]]

[[date:2022-01-11T00:00:00.000Z]]

[[continent:Africa]]

[[country:Kenya]]



Evaluating Crowdsourcing
Behaviours in Identifying
Online Misinformation

An Experimental Evaluation of the Healthy
Internet Project

September 2021

About Us

UNDP Accelerator Labs

Busara Center for Behavioral Economics

The United Nations Development Programme

(UNDP) is the leading United Nations organization

ﬁghting to end poverty, inequality, and climate

change. The UNDP Accelerator Labs is the world’s

largest and fastest learning network on wicked

sustainable development challenges. The network

of 91 labs covers 115 countries and taps Into local

innovations to create actionable insights and

reimagine sustainable development for the 21st

century. Learn more at acceleratorlabs.undp.org or

follow us at @UNDPAccLabs

Busara is a research and advisory ﬁrm dedicated

to advancing and applying Behavioral Science in

the pursuit of poverty alleviation in the Global

South. Busara is spread across 5 ofﬁces in Africa

and Asia; and works with clients to enable them

to understand behaviors, and to design and test

solutions to scale their interests. Busara has

completed strategic partnerships with an array of

private-sector organizations, as well as with

governments, with NGOs, and with academic

institutions, that are interested in leveraging

behavioral science insights to improve upon

outcomes. Learn more at: www.busaracenter.org

2

Acknowledgements

We would like to thank Renae Reints, Anand Upender and the entire

technical team at the Healthy Internet Project for their support and

input to the research, and for offering guidance where necessary.

We would like to thank Enock Nyariki, Christine Mutisya, Jessica

Manim, Doreen Wainainah, and Collins Nabiswa for their time,

efforts and contributions to the ﬂag quality check exercise. We

would like to thank Caroline Kiarie-Kimondo and Victor Awuor from

UNDP Kenya for their Insights, guidance and feedback on this

research.

How to cite this report:

Canagarajah, R., Ogutu, B.,

Mugi, N., Too, G., Njoro, L.
(2021). Evaluating

Crowdsourcing Behaviors In

Identifying Online
Misinformation.

List of Abbreviations

UNDP - United Nations
Development Programme

HIP - Healthy Internet
Project Incubated at TED

TED - Technology,
Entertainment, Design

3

Table of contents

➔ Executive Summary

➔ Introduction

➔ Key Findings

➔ Evaluation Methods

➔ Detailed Findings

➔ Recommendations from Full Study

5

9

12

16

29

84

Executive
Summary

Brief overview of project activities, a summary of ﬂagging trends
and our recommendations

Executive Summary: Part 1
Busara conducted a live experimental demonstration of the
Healthy Internet Project (HIP) plugin, in collaboration with
UNDP Accelerator Lab Kenya, and the Healthy Internet
Project (HIP) incubated at TED. The Healthy Internet Project
plug-in (displayed on the right) is an open source web browser
extension that allows users to ﬂag content online; it is intended
to help curb the spread of lies, abuse, and fear mongering, as
well as to uplift useful ideas on the internet. Users are able to
mark ﬂags as mild / minor, medium, or severe across the latter
ﬂagging categories.

Our experimental design sought to understand potential users’
motivations, experiences, and practices in using the
volunteer-driven, crowdsourcing platform to ﬂag
misinformation in a live experiment which encouraged natural
behaviors.

Executive Summary: Part 2
We onboarded 205 users but only 128 used the platform. We followed up with 44 of these users in a
qualitative exercise. In user patterns of ﬂagging, the large majority of our respondents - also referred to as
users- (N=109) fell into the Low Flagging Group (i.e., less than 5 ﬂags). The majority of respondents (75%)
ﬂagged Worthwhile content. In user perceptions, there were concerns that ﬂagging negative content was
1) more subjective; 2) might have led to harmful repercussions for those who are ﬂagged; and 3) was
personally risky, especially vis a vis political content. In terms of user accuracy, “misinformation” was
viewed through negative user sentiments, such as a dislike for a topic, rather than as misinformation itself.
Moreover, it was difﬁcult for external fact checkers to know what constituted misinformation amongst
ﬂagged content, because the majority of ﬂag-level comment sections went unused (81% of ﬂags), or were
ill used i.e., users hardly speciﬁed exactly what was misinforming about the websites they were on.

We conclude that the value-add of volunteer driven misinformation identiﬁcation is limited without

changes to user perception of safety, and of accuracy. There is need for a better understanding of

misinformation to enhance objectivity in ﬂagging activity. In order to improve platforms like HIP, we share

the following recommendations:

Executive Summary: Part 3
● User Experience

○ Ensure Anonymity: There should be more details to convince users of their anonymity to address the risks

they feel on reporting misinformation.

● User Accuracy

○ Provide a Misinformation Introduction: We believe a primer on misinformation should be present to increase

accuracy of user reports.

○ Remove Worthwhile Flag: We also believe there is value in reconsidering and potentially removing the

Worthwhile ﬂag to solidify the purpose of the plug-in.

○ Add a Required “Misinformation Identiﬁcation” Field: Finally, for the ease of fact checkers, we recommend

adding a required ﬁeld in which users specify the content they deem as misinformation. This should not be

the website URL, but the actual content they believe to be misinformation.

Introduction

Project timeline, project background,
and project activities

Project Background
■ UNDP and the Healthy Internet Project, incubated at TED engaged in a partnership to accelerate
testing and to generate actionable data on TED’s Healthy Internet Project (HIP) and its prototype
tool. This crowdsourcing tool helps to identify and review worthwhile ideas as well as harmful
content found on the internet. UNDP Kenya, through the Accelerator Lab, has partnered with Busara
to conduct a pilot study in Kenya with a prototype of the HIP platform.

■ The objectives of this study were to explore the following learning themes:

Usage patterns

Use motivations
and barriers

User accuracy

Value proposition in
addressing misinformation

■ With a view to analyzing user accuracy, we engaged the support of PesaCheck, Africa’s largest
indigenous fact-checking organisation, to validate a sample of the claims associated with ﬂagging
activity from the study.

Busara Center For Behavioral Economics | 2021

10

Project Timeline

Phase 0: Stakeholder Alignment

Phase 2: Mixed Methods Behavioral Mapping

In collaboration with the UNDP
Accelerator Lab Kenya, we proposed to
conduct a study with the HIP platform to
develop a deeper understanding of
potential motivations and barriers for
platform users.

We used mixed methods in-depth interviews and a focus
group discussion to analyze behavioral factors relevant to user
engagement in crowdsourcing reporting approaches; with an
aim to understanding context-speciﬁc motivations and barriers
to HIP plug-in use.

JUNE - JULY 2021

SEPTEMBER 2021

APRIL 2021

AUGUST 2021

Phase 1: Live Demonstration

Phase 3: Communications & Reporting

We recruited 205 study participants from its
database to pilot the HIP plug-in; we observed
participant behavior across three key domains:
user experience, user motivation, and user
reporting accuracy.

In this stage, we shared with UNDP insights from the
study and recommendations on the way forward. We
also collaborated with both organizations in creating
blogs and publicly accessible documentation on our
evaluation.

Busara Center For Behavioral Economics | 2021

11

Key Findings

Overview of key ﬁndings based on
quantitative and qualitative insights

On User Motivation and Perceptions

Majority Have Never Reported

Belief that HIP is a Good Tool

Many respondents had never reported
misinformation before HIP, despite knowing other
methods. A smaller amount (<10) from
qualitative study say that they ﬂagged
misinformation in other ways (i.e., Safaricom,
report buttons).

Participants consider HIP an appropriate tool for
stopping the spread of misinformation. This tool may
present a more formal approach to ﬂagging
misinformation given its explicit purpose in achieving
this compared to social media avenues.

Risk in Reporting: Anonymity

Risk in Reporting: Repercussions

Users fear that they will be identiﬁed through
platform use, especially for political or
relevantly sensitive information. When it
comes to political actors, users are
unconvinced of the platform’s promise.

Users do not know if their report on misinformation
is accurate (i.e., objective vs. subjective). Moreover,
they fear their actions may lead to negative
consequences for those behind the websites or
articles identiﬁed, or to themselves.

13

On User Engagement

Overwhelming Use of Worthwhile

Most Use on Weekday Morning

Despite the intent to stop the spread of
misinformation, most people use the tool to
ﬂag worthwhile content. The Worthwhile ﬂags
constituted the majority of ﬂags (75%) used by
our participants.

User analysis suggests that our respondents
used the platform most during weekday
morning hours, and very infrequently over the
weekend.

Lies+Manipulation Most “Severe”

Barriers in Continued Use

Despite Worthwhile being the most popular
ﬂag of use, it often received minor rankings.
Lies and Manipulation however received the
highest severity levels among all ﬂags.

Internet challenges and not frequently coming across
harmful content partly explains the low usage of HIP.
Other barriers include only being bound to PC for HIP
use, and the lack of feedback mechanisms (i.e.,
receiving an update on the actions taken by the
provider). Monetary incentives could increase usage of
HIP.

14

On User Accuracy

Mixed Self Perceptions on Accuracy

PesaCheck: Lack of Validation

Some respondents believe that they ﬂag
accurately, despite the study ﬁnding otherwise
in the monitoring phase. Yet others are not
conﬁdent or comfortable in their interpretation
of how to ﬂag misinformation

Based on PesaCheck ﬁndings of 10 core ﬂags,
ﬂagged content was shown to be
sentiment-driven and often too broad to say
what element of a website was misinformation
or not.

Misinformation Trainings

Core Attention on Worthwhile Flag

Many users strayed away from ﬂagging
misinformation for two reasons: 1) they were
not comfortable in the subjectivity; and 2) they
did not want to harm anyone. Trainings and
deﬁnition activities on misinformation and
what happens post-ﬂag validation could
address this.

Qualitative ﬁndings showed that more people than
expected do more research on the validity of
worthwhile content, than for harmful content.

15

Evaluation Methods

Insights into the live experiment, data analysis
and qualitative follow-ups

Quantitative
Live Experiment
Overview of live experiment
approach, data analysis
limitations, and demographics

Purpose of the live experiment study:

To use a live experiment to observe
“natural”* behaviors on the platform,
leading to understanding user experience,
user motivations, user accuracy, and
segmented demographic trends of platform
use based on volunteered** engagement.

*We exposed and trained users on the HIP platform, therefore their behaviors on the platform may not have been entirely natural.
However, we did not have any other contact with them during the run of the live experiment.

**Respondents were not incentivised or paid to report. It wasn’t until after the study that they knew they would be compensated.

18

Live Experiment Approach

Live Experiment Set-Up

Prior to the evaluation, we
determined demographics and
locations of interest, particularly
those on internet usage/access. We
then designed a light-touch
onboarding script to encourage
natural behaviors and created a
pre-analysis plan (PAP) based on
metrics of interest.
Onboarding

Based on demographics
segments, we used stratiﬁed
random sampling, to recruit 205
ﬁnal respondents (from Busara’s
existing database) in a staggered
timeline, After each respondent
was onboarded through the script,
we collected user HIP IDs and
merged them with Busara IDs.

04

01

03

02

Data Analysis and Findings

After respondents ended their 4 week
trial of the HIP platform, we analysed
usage patterns by demographics; user
perceptions/ attitudes towards the
platform; types of ﬂags raised; and
validity of ﬂags, among other factors.
we pre-coded ﬂag categories and user
behaviors according to trends in the
data.

Live Demonstration

After light-touch onboarding, we
allowed users to engage with the
platform at their own will for 3+
weeks. Respondents were
monitored on their HIP platform
usage.

Busara Center For Behavioral Economics | 2021

19

Summary for Live Experiment

371

Total Number
of Flags

57%

Male

43%

Female

128

Total Number of Users
(Post-attrition)

Busara Center For Behavioral Economics | 2021

20

Demographic Summary for Live Experiment

Age Group

Education

Ethnic
Group

Location

18 - 24

25 - 39

40 - 49

50 - 60

--

--

--

--

42%

52%

5%

≃ 1%

Primary

--

< 1%

Secondary --

44%

Post -
Secondary -- 65%

Gĩkũyu
Luo
Kamba
Kisii
Luhya
Meru
Kalenjin
Maasai

Turkana

--
--
--
--
--
--
--
--

--

43%
17%
13%
9%
8%
5%
4%
2%

1%

Kiambu

Nairobi

Machakos

Kajiado

Muranga

--

--

--

--

--

34%

33%

19%

10%

5%

Busara Center For Behavioral Economics | 2021

21

The study participants were onboarded on a
staggered schedule

■ User participation in the onboarding sessions was determined at random. All respondents were exposed to at

minimum 2 weeks on the platform. Onboarding entailed: explaining the study, guiding respondents in downloading
the tool, and a practice session of ﬂagging content.

Busara Center For Behavioral Economics | 2021

22

Limitations in Data and Analysis

1. Non-Participation: Of the 128 onboarded study participants for whom data was

included in this analysis, only 40% ﬂagged more than one (1) item using the HIP plug-in

-- reducing data diversity thereby impeding generalizability of the conclusions from this

analysis.

2. Representation: 100% of study participants considered in this analysis, identiﬁed as

Christian; < 1% had completed primary school education . This means that we cannot

generalize the ﬁndings to a wider population since the whole population has varied

religious denominations and education levels.

Busara Center For Behavioral Economics | 2021

23

Limitations in Data and Analysis (CONT.)

3. Broad categories: Comment categories are deﬁned

broadly (as illustrated on the right) -- narrower deﬁnitions

would have required claim categorization at the individual

comment level -- a task for which we were not able to

bring capacity to bear upon for this project.

81%

No Comment /
User ID

Comment Categories:

9%

Hashtag(s)

24

9%

Comments with
claims

Qualitative
Interviews
Overview of our follow-up
qualitative approach and
demographics

Purpose of the qualitative study:

To understand context speciﬁc insights as
it relates to users’ demographics and
motivations, and to get a more nuanced
understanding of the ﬁndings captured in
the live experimentation phase.

26

Qualitative Approach

Design of Qualitative Tools

We designed a qualitative
instrument that was reviewed
and approved by UNDP.

Conduct In-Depth Interviews
(IDIs) and Focus Group
Discussions (FGDs)

We conducted 39 phone in
depth interviews and 1
in-person focus group
discussion between August
24th 2021 and August 27th
2021. They were conducted
with people from 9 counties.

04

01

03

02

Presentation of Findings

The analysis of the qualitative
data brought out key ﬁndings
that then informed the
recommendations relevant for
UNDP.

Analysis of Findings

The audio ﬁles from the in depth
interviews and focus group
discussions were transcribed
and thereafter analyzed.

Busara Center For Behavioral Economics | 2021

27

Demographic Summary for the Qualitative Study (N=44)

We conducted in depth interviews with 39 individuals, and held one focus group discussion with 5
people. Below is the demographic breakdown of this sample:

Age Group

Gender

20-25 - 65%
26-30 - 21%
31-35 - 14%

Male - 49%
Female - 51%

Education

Marital Status

Secondary School - 25%
Tertiary Education - 75%

Single - 87%
Married - 13%

Busara Center For Behavioral Economics | 2021

28

Detailed Findings

Insights into user backgrounds, user HIP practices, segmented
user insights, user accuracy, and user motivations

HIP User
Backgrounds

Overview of user practices on the internet and
exposure to misinformation

As expected, internet usage is prevalent amongst our
respondent pool, which consists mostly of youth.

Personal Interests

Computer Proﬁciency

■ Our respondents were split equally in terms
of paying attention to current affairs or not;
while most respondents pay attention to
social media. Additionally, most of the
respondents have volunteering experience
which they see as a prosocial responsibility.

■ Most of the respondents stated that they have
advanced skills in computer use, with average
years of computer usage being between 5 and
6 years.

Digital Services Usage

Internet Usage

■ All the respondents use both their phone
and laptop or computer to access the
internet. Phone usage is however
predominant because of its portability and
ease of information access. Laptops are
mostly used for work.

■ Most participants use the internet to access

information and share it with others. Many of
them receive information from others through
their social media platforms, and only a few
access information from mass media channels,
i.e., TV and radio.

Busara Center For Behavioral Economics | 2019

31

Mass media channels, speciﬁcally televisions, are the most
trusted source of information.
Data:
■ Social media is the preferred method of accessing

information. Some people attributed this preference to
the convenience and accessibility of accessing it
through the phone, compared to TVs and the radios.

■ However, many participants cited that TVs are the
most trusted source, because of the veriﬁable
information they share, as opposed to rumors
occasionally spread on social media platforms.

Analysis & Implication: Phones are convenient and easily
accessible, which means that these are important tools to
leverage and prioritize in the misinformation space. A
phone-compatible version of the HIP tool will increase
usage.

“Because I am mostly on
my phone and I can easily
access it.”
Female, 34yrs, Kajiado.

“Before something is
posted it must be edited
and so you trust it (TV).
For social media, it might
be rumors, there might be
exaggeration and the
likes.”
Female, 23yrs, Laikipia

“Mass media i.e., TV.
because at least
when they air
something, it is
something that you
can see and they
provide the
evidence. But when
you talk about things
like twitter, it can be
manipulated.”
Female, 23yrs,
Nairobi

Busara Center For Behavioral Economics | 2021

32

It is important for all the respondents that information is
ﬁrst veriﬁed before sharing.
Data:
■ All the respondents emphasised the importance of
verifying information ﬁrst before sharing, in order to
avoid misleading the public, spreading false
information and rumors that might cause panic or fear.

"To avoid spreading
rumors. Checking other
Medias to see what they
are saying about the
something."
Male, 23yrs, Kiambu

■ Most participants relied on their social network, like

family, relatives, or friends to verify the information for
them. On the other hand, some people indicated that
they depend on their instincts to verify the content of
the information themselves.

Analysis & Implication: Pair misinformation tools with
education and awareness on effective ways of verifying
information. This prevents users from ﬂagging content
based on their instincts or feelings.

"The degree of certainty is
high when I do it on my
own but when I am not
certain on the subject I
might consider doing so."
Male, 28yrs, Nairobi

“It is important
because maybe you
could be sharing
information that is
not true and you
don’t have any
information about it
and you can’t even
defend it. When you
share something
that is misleading,
then it won’t look
good.”
Male, 22yrs,
Machakos

Busara Center For Behavioral Economics | 2021

33

Besides HIP, some respondents were aware of other ways
of reporting misinformation.
Data:
■ Some respondents were aware of other ways of

reporting misinformation including:
□ Calling the providers' contact number on the

website to report the misinformation

□ Sending emails to the related sites, where the

misinformation was found

□ Using the report button or icon of the social media

platform

□ Reporting to the police
□ Reporting to Safaricom (though they could not

explain this method)

Analysis & Implication: Reporting via social media was the
most common because it was the only way people were
aware they could report misinformation. This brings up,
again, the need for creating more awareness on HIP.
Busara Center For Behavioral Economics | 2021

“In the social media
platforms there is a report
button, that can be used
to report misinformation.”
Male, 22yrs, Machakos

“With email you can
forward the
misinformation to the
email account of the
related sites.”
Female, 23yrs, Kiambu.

“For now maybe I
use HIP but the
problem is
information passed
by word of mouth
cannot be reported
in HIP.”
Male, 23yrs,
Kirinyaga

34

HIP User Experiences
& Practices on HIP

Overview of general user behaviors and
patterns on the HIP platform

S
R
E
V
E
L

I

S
R
E
R
R
A
B

Summary of User Engagement and Experience with HIP

Improves the quality of
information spread on the
internet

Misleading content can be
taken down, so less people
see it.

In future posts, ﬂagged sites
will take caution not to share
misinformation.

Easy to use: Simple interface
with simple and clear
language.

Users are completely
anonymous.

A few times the HIP tool fails
to respond when a user clicks
on it, therefore there are
some delays.

Lack of clarity on ﬂag
deﬁnitions: There is a bit of
confusion on the ﬂag
deﬁnition is appropriate for
certain types of content.

Lack of internet (bundles)
and slow/ unstable internet.

Limited browsers that can
support the HIP tool.

What you ﬂag is permanent,
you cannot correct a mistake
if you made one.

Busara Center For Behavioral Economics | 2021

36

Overall Flagging
Usage
Relationships between ﬂagging
behavior by demographic and
non-demographic variables

People use HIP because they consider it an appropriate
tool for stopping the spread of misinformation.

Data:
■ Most of the respondents had used the HIP tool to

ﬂag misinformation. The main reason people use the
HIP tool is because they believe it's a good and
highly appropriate tool to: help indicate useful or
important content; help people verify information
and remove harmful content; and help stop the
spread of misinformation.

■ Other reasons that came from a few respondents is
that it's very fast and easy to use, and they trust it.

Analysis & Implication: The study found that HIP is
appropriate, easy to use and can change the quality of
content online, and this conﬁrms the need for such a tool,
available to the general public.

"Because I thought that it
was the most appropriate
tool to use.”
Male, 23yrs, Nairobi

“It is something I like to do
so that I can help build an
honest society and also to
prevent misinformation
and disinformation.”
Male, 28yrs, Nairobi

“I trust it. So far have
not had had any
issues with it.”
Male, 23yrs, Kajiado

Busara Center For Behavioral Economics | 2021

38

Users between 18 to 24 years old were the most
active on HIP; and accounted for ≃ 57% of all ﬂags.

The proportion of ﬂags analyzed by age
group:

■ 18 - 24 years:

57% of ﬂags (205)
42% of user population

■ 25 - 39 years:

40% of ﬂags (143)
52% of user population

■ 40 - 49 years:

3% of ﬂags (13)
5% of user population

■ 50 - 60 years:

.3% of ﬂags (1)
1% of user population

Busara Center For Behavioral Economics | 2021

39

Female users registered a higher average number of
ﬂags per category than did male users
By gender, the total and the average
numbers of ﬂags per category were:

■ Worthwhile Ideas

Male:
Female: Total = 166 Average ≃ 3

Total = 120 Average ≃ 1.6

■ Lies or Manipulation

Total = 30 Average ≃ .4
Male:
Female: Total = 9 Average ≃ .2

■ Abuse or Harassment

Average ≃ .2
Male:
Female: Total = 10 Average ≃ .2

Total = 12

■ Division or Fear

Total = 12
Male:
Female: Total = 12

Average ≃ .2
Average ≃ .2

Busara Center For Behavioral Economics | 2021

40

On average, more ﬂags were registered by users
from the Meru, Luo, Gĩkũyũ, and Kisii communities.

■ Gĩkũyũ (165 ﬂags total per user), Meru (25 ﬂags),
Luo (65 ﬂags), Kisii (32 ﬂags), Kamba (41 ﬂags),
Kalenjin (13 ﬂags), Luhya (16 ﬂags), Maasai (4
ﬂags), Turkana (1 ﬂag)

■ Gĩkũyũ (3 ﬂags average per user), Meru (4.3 ﬂags),
Luo (3.3 ﬂags), Kisii (3 ﬂags), Kamba (2.5), Kalenjin
(2.6), Luhya (1.6), Maasai (2), Turkana (1)

Busara Center For Behavioral Economics | 2021

41

On average, users from Kiambu were more active

Total numbers of ﬂags by location:

Average numbers of ﬂags by location:

■
Kiambu - 122 ﬂags
■ Nairobi - 118 ﬂags
■ Machakos - 67 ﬂags
■
Kajiado - 36 ﬂags
■ Muranga - 19 ﬂags

Kiambu - 19 ﬂags

■
■ Nairobi - 7 ﬂags
■
Kajiado - 6 ﬂags
■ Machakos - 6 ﬂags
■ Muranga - 4 ﬂags

Busara Center For Behavioral Economics | 2021

42

On average, users with a secondary school level of
education were more active.

Total numbers of ﬂags by level of education:

Average numbers of ﬂags by level of education:

■ Post-secondary - 199 ﬂags
■
Secondary - 162 ﬂags
■ Primary - 1 ﬂag

■
Secondary - 16 ﬂags
■ Post-secondary - 6 ﬂags
■ Primary - 1 ﬂag

Busara Center For Behavioral Economics | 2021

43

Besides search results, social media posts and articles
were the most ﬂagged type of content.

Legend:

● News
● Government Notiﬁcations
● Universities
● Activist Organizations
● Businesses and Services
● Social Media Posts
● Search Results
● Sports
● Attempted Email
● Recipes
● Miscellaneous

➔ Themes included in

Miscellaneous: health, art,
self-help, natural science,
events, and ﬁnance.

Busara Center For Behavioral Economics | 2021

44

Academic and sports are the most ﬂagged type of
articles.

Data:
■ Most people ﬂag content in articles such as

academic articles, sports articles and articles on
politics.

■ Many people ﬂag content in social media (i.e.,

Facebook, Youtube, LinkedIn) and blogs, while a few
people ﬂag journals, online newspapers, and general
websites on health, money, jobs, and scholarships.

Analysis & Implication: Despite the risk people attached
to ﬂagging political content, the study ﬁndings show that
a good percentage of users still ﬂag them. This shows
that their social responsibility outweighs their personal
safety.

“Articles and blogs because
most of the time they are the
writer’s opinions.”
Female, 23yrs, Kiambu

“Football articles and
website, newsletters and
some other apps like
FlashScore* [which shares
live football scores].”
Male, 25yrs, Nairobi

“Mostly on politics and
from articles.
This is because people
mostly concentrate on
politics.”
Male, 22yrs, Machakos

Busara Center For Behavioral Economics | 2021

45

Mornings (7-11am) registered a relatively higher
number of ﬂag count

■ Hour of the day with the highest

number of ﬂags is 8:00am.

■ Hour of the day with lowest
number of ﬂags is 3:00am.

Busara Center For Behavioral Economics | 2021

46

The tool does not require much time so it is used by
respondents at any time during the day.

Data:
■ The tool is not too involving, so it doesn't take much
time, therefore, many people use it for less than an
hour in a day. One person who says it takes time is
because they included the time involved in reading
what they want to ﬂag.

■ Some respondents mentioned that they use the tool
anytime, and so have no time preference since it
does not take much time to use the HIP tool.

Analysis & Implication: A phone version of HIP can
increase usage as people can make use of their other
free times like during commutes, and meal times.

“Anytime, it’s something
that you pop in and send,
it doesn’t even take 20
seconds.”
Male, 22yrs, Machakos

“Mid morning and
afternoon between
10am to 2pm, that’s the
time when I’m more
active in the internet.”
Female, 23yrs, Kiambu

“I use it whenever I
feel I need to use
it.”
Male, 23yrs, Siaya

Busara Center For Behavioral Economics | 2021

47

Weekends registered relatively lower numbers of
ﬂags.

■ Day of the week with highest

number of ﬂags is Wednesday.

■ Day of the week with lowest
number of ﬂags is Sunday.

Busara Center For Behavioral Economics | 2021

48

Usage by Flag
Deﬁnitions
Assessing usage by ﬂag
deﬁnitions

Overview of Usage by Flag Deﬁnition and the
Demographic Breakdown
Worthwhile Ideas

Abuse or Harassment

■ Total number of ﬂags: 268
■ Median rank on the severity scale:

Minor

■ Female: 58%
■ Post secondary education: 54%
■ 18 - 24 age group: 59%

■ Total number of ﬂags: 22
■ Median rank on the severity

scale: Minor
■ Male: 55%
■ Post secondary education: 41%
■ 18 - 24 age group: 55%

Lies or Manipulation

Division or Fear

■ Total number of ﬂags: 39
■ Median rank on the severity scale:

Severe
■ Male: 77%
■ Post secondary education: 74%
■ 18 - 24 age group: 49%
■ 25 - 39 age group: 49%

■ Total number of ﬂags: 24
■ Median rank on the severity

scale: Minor
■ Female: 50%
■ Post secondary education: 46%
■ 25 - 39 age group: 63%

Busara Center For Behavioral Economics | 2019

50

Despite their intent to stop the spread of misinformation,
most people use the tool to ﬂag worthwhile content.

Data:
■ Most people use the HIP tool to ﬂag worthwhile
content, while many people use it to ﬂag both
worthwhile and harmful content. Some people use it
to ﬂag misinformation or harmful content that they
ﬁnd online.

■ One person only ﬂagged worthwhile content

because they described themselves as positive and
thus they only spread information that can help
someone. Another reason from another user is
wanting to contribute to the society.

Analysis & Implication: As mentioned earlier, having the
option to ﬂag worthwhile content reduces the quantity of
ﬂags related to harmful content.

“It cannot lead to cyber
bullying and the likes. I
have mostly used it to
spread worthwhile ideas.”
Female, 23yrs, Nairobi

“I used it to share
worthwhile ideas. The
article was about how we
can mitigate climate
change, corals and I was
just giving my idea and
opinions. Adding to what
they said.”
Female, 23yrs, Nairobi

“I am a positive
person so I only ﬂag
the positive ones
that can help
someone.”
Female, 34yrs,
Kiambu

Busara Center For Behavioral Economics | 2021

51

A large majority of ﬂags were in the “Worthwhile
Ideas” category.

■ Worthwhile Ideas: 73.9%

■ Lies or Manipulation: 10.1%

■ Abuse or Harassment: 9.8%

■ Division or Fear: 6.2%

Busara Center For Behavioral Economics | 2021

52

More people than expected do more research on the
validity of worthwhile content, than for harmful content.

Data:

■ Most people use their personal judgement, often a hunch

but sometimes through research, to decide whether the
information they are ﬂagging is worthwhile content. They
do not receive any help in making the decision to ﬂag
because they believe in their own judgement or don't
believe someone else will give them any new information
that they do not already have.

■ On the other hand, to verify the information, some people
ask their social network like family, friends and peers; but
mostly from friends. Many people prefer asking friends
because they rely on them for guidance in areas or topics
that they are not familiar with and they are also
comfortable with them since they have known them for a
long time.

“When I go through
articles I look at the
source, like if I get from
New York Times or BBC. I
know it's a reliable source
because they are
reputable media. One
thing I look at is the
publisher and the content
of the article to see
whether the writer has
cited renowned people
who are experts in a
particular ﬁeld.”
Female, 30yrs, Kiambu

“There is what you
expect when
researching on
something so I used
that judgement and
no one inﬂuenced
my decision I was
just ﬂagging the
worthwhile ideas.”
Male, 22yrs,
Machakos

Busara Center For Behavioral Economics | 2021

53

More people than expected do more research on the
validity of worthwhile content, than for harmful content.

Data:
■ Some people determine that the information is

worthwhile if it is useful for them for what they are
doing.

■ While some people do their own research and check
for reliable and credible sources, citations, credible
publishers, known media houses (i.e., NTV and KTN)
and trusted websites.

■ Some check on feedback or ratings given on the site

by other people. A few people check whether
evidence has been attached (i.e., videos, photos).
Analysis & Implication: This explains why users provide
more information when it comes to worthwhile content,
making it easier to verify the quality of such ﬂags.

"By checking on the
content of the
information. I also look
at the source of the
information are they
credible. And also the
different citations. Also
checking on the
feedback given on the
same content."
Male, 28yrs, Nairobi

“If it helps me with
whatever I wanted
like if I was searching
for something and I
get the correct
information I consider
that as worthwhile
content.”
Female, 23yrs,
Kiambu

Busara Center For Behavioral Economics | 2021

54

Most people rely on their personal judgement to verify
the quality of harmful content.

Data:
■ Most people either use their personal judgement to
determine whether the information is harmful
content or check to see whether it would be harmful
to them or others in the society.

■ Some people check whether the content is targeting
only certain groups of people and others use other
sources or research to verify the information. Some
people rely on their social network e.g community
norms, peers, to help them verify whether the
content is harmful. A few people review the
feedback on the sites and check the sources.

Analysis & Implication: In terms of identifying harmful
content, there is a huge lack of objectivity which reduces
the quality of ﬂags.

Busara Center For Behavioral Economics | 2021

“The fact that I’m learned helps me know what
is harmful and what is not so i just use my
personal opinion.”
Female, 23yrs, Kiambu

“Discuss with my friends and if most of them
see the information as harmful then it is
harmful.”
Male, 24yrs, Mombasa

55

Analysis by
Flagging Severity
Trends in ﬂagging analyzed by
ﬂag categories -- organized into
severity ranks on a set severity
scale running from “Minor” to
“Medium” to “Brilliant / Severe”

People rely mostly on their personal judgement when it
comes to attaching a severity level to a ﬂag.

Data:
■ Most people choose the severity level based on their
own judgement or intuition; they read the content
and check how it affects them or other people.

■ For example, rape would severely affect them so it
gets a severe rating while content on sports might
not be severe.

Analysis & Implication: Users are not entirely sure how
to use the severity rating, it could be based on how the
content made them feel or whether it targets certain
groups.

This feature needs a bit more clarity; more information
can be provided so that users are on the same page
about how to use it.

“You just make a
judgement. For
example if a girl was
raped somewhere and
someone is saying
that it was their fault
or they are making fun
of that, it is severe.
Then if it is just a joke,
that one is not severe."
Female, 23yrs, Laikipia

“Severity level varies
from one person to
another so what is
misleading to me
might not to another
person. I just use my
intuition.”
Female, 23yrs,
Kiambu

Busara Center For Behavioral Economics | 2021

57

Severity levels differed by category, with Lies and
Manipulation tending towards most severe rankings.

● Division or Fear received the most

‘minor’ rankings on the severity scale.

● Abuse or Harassment received the

most ‘medium’ rankings on the

severity scale.

● Lies or Manipulation received the

most ‘severe’ rankings on the severity

scale.

● Abuse and Harassment received the

least ‘severe’ rankings on the severity

scale.

Busara Center For Behavioral Economics | 2021

58

Segmented User
Insights

Analysis of user segmentation,
based on high, mid and low
ﬂagging users

Only 3 people were considered Active Users (Flags > 15)

75

Total Number
of Flags

44%

56%

3

Proportion of ﬂags
registered by Male users

Proportion of ﬂags
registered by Female users

Total Number of Active
Users

Busara Center For Behavioral Economics | 2021

60

Demographic summary for the 75 ﬂags registered by
Active Users

Age Group

Education

Ethnic
Group

Location

18 - 24

25 - 39

--

--

83%

17%

Secondary -- 73%

Post-Secondary -- 27%

Gĩkũyu
Luo

--
--

83%
17%

Kiambu

Nairobi

Machakos

--

--

--

56%

27%

17%

Busara Center For Behavioral Economics | 2021

61

16 users were considered Moderate Users ( 5 < Flags < 15)

130

Total Number
of Flags

29%

71%

16

Proportion of ﬂags
registered by Male users

Proportion of ﬂags
registered by Female users

Total Number of Active
Users

Busara Center For Behavioral Economics | 2021

62

Demographic summary for the 130 ﬂags registered by
Middle Users

Age Group

Education

Ethnic
Group

Location

18 - 24

25 - 39

40 - 49

--

--

--

60%

34%

6%

Secondary -- 37%

Post - Secondary -- 63%

Gĩkũyu
Kisii
Kamba
Luo
Meru
Kalenjin

--
--
--
--
--
--

29%
18%
16%
16%
16%
5%

Nairobi

Kiambu

Kajiado

Machakos

Muranga

--

--

--

--

--

39%

26%

10%

19%

6%

Busara Center For Behavioral Economics | 2021

63

A majority of users were considered Low Users (Flags < 5)

157

Total Number
of Flags

62%

38%

109

Proportion of ﬂags
registered by Male users

Proportion of ﬂags
registered by Female users

Total Number of Active
Users

Busara Center For Behavioral Economics | 2021

64

Demographic Summary for the 109 ﬂags registered by
Low Users

Age Group

Education

Ethnic
Group

Location

18 - 24

25 - 39

40 - 59

50 - 60

--

--

--

--

42%

55%

3%

< 1%

Secondary --

37%

Post-Secondary -- 62%

Primary

--

≃ 1%

Gĩkũyu
Luo
Kamba
Luhya
Kisii
Kalenjin
Maasai
Meru
Turkana

--
--
--
--
--
--
--
--
--

41%
20%
13%
10%
6%
5%
3%
3%
≃ 1%

Kiambu

--

Nairobi

--

Machakos

--

Kajiado

Muranga

--

--

30%

30%

19%

15%

6%

Busara Center For Behavioral Economics | 2021

65

There are varied reasons for people not using the HIP
Platform.

Data:
■ 75% of the people stated that they rarely use the HIP
tool, that is, once a week to more than once in a
month. The main reasons for not using the HIP tool
include: rare usage of the internet (i.e., lack of
bundles), not having a computer, not having time to
ﬂag, not coming across any harmful content, and the
tool itself is not salient to them.

■ The behavioural reasons include not wanting or liking
to report other people and not being able to complete
reporting after starting the process. One respondent
thought that “people are reckless” so there is no point
in reporting (i.e., misinformation will exist anyway).

“Yes, for worthwhile ideas,
but for reporting no
because nothing has
come my way yet.”
Female, 34yrs, Kajiado

"Unless I become a
blogger or someone that
uses the internet all the
time. If it can become like
a job, then I can be using
it severally."
Male, 25yrs, Nairobi

“No, because I don’t
like reporting things
but when there is a
lot of rumours being
spread and I have
the correct facts i
would be motivated
to report.”
Male, 22yrs, Nairobi

Busara Center For Behavioral Economics | 2021

66

Internet challenges and not frequently coming across
harmful content partly explains the low usage of HIP.

Data:
■ Rare usage was attributed to internet issues, no

option to report accounts, not being able to use it on
the phone, forgetfulness, and they don't use the
platform everytime they are online since it's not all
the time that something needs to be ﬂagged.

■ For the available data on moderate users, there

“Not every time that I’m
online but only when it's
necessary that's when I
get to use it.”
Female, 28, Machakos

were a few varied reasons for why they keep using
HIP, including a sense of responsibility, to ensure
healthy internet usage, novelty of the tool,
effectiveness of the tool, and the anonymity aspect.

“Because we tend to ﬂag
things that are negative
and they are not many."
Male, 23yrs, Nairobi

“I spend most of my
time on the phone
and not on the
laptop and when I
am using the laptop
most of the time it’s
when I need to do
something
important.”
Female, 34yrs,
Kajiado

Analysis & Implication: There is a likelihood that HIP will
be used more by middle-upper class citizens since the
low income users always think about the ﬁnancial costs.

Busara Center For Behavioral Economics | 2021

67

User Accuracy

Assessment of user accuracy
in ﬂagging misinformation from
ﬂag sample validation exercise
by PesaCheck

PesaCheck found that respondents tend to use emotional
reactions when ﬂagging, as opposed to objectivity.

PesaCheck analyzed the validity of claims associated with ﬂags from a sample of 15
ﬂags (4%) that were registered by users for the study.

1. Claims made about ﬂags that were in the Worthwhile Ideas category, were on average more
relevant and more ﬂeshed out than claims made in any of the other 3 ﬂag categories: Lies or
Manipulation, abuse or harassment, and Division or Fear.

2. Many of the claims from the sample that were associated with Division or Fear ﬂags were

made about websites that featured political subject matter.

3. PesaCheck found that claims associated with the relevant ﬂags in the sample derive more

users’ emotional reactions to website content rather than empirical disagreement with the
content itself.

4. For some claims, aggregation at the website level (as opposed to the individual ﬂag level)

would have made it difﬁcult to identify what aspects of each claim to fact-check.

Busara Center For Behavioral Economics | 2021

69

Respondents believe that they ﬂag accurately, despite the
ﬁnding from PesaCheck.

Data:
■ Most people generally understand the ﬂagging
deﬁnitions and a large majority believe that the
ﬂagging deﬁnitions are easy to understand.

■ Most people believe that they accurately ﬂag based
on the ﬂag deﬁnitions (i.e., Worthwhile, Lies and
Manipulation, Abuse and Harassment, Division or
Fear). On a scale of 1 to 5, 45% rate themselves at a
4 while 39% rate themselves at a 5, when it comes
to accuracy.

Analysis & Implication: It is expected that people believe
that they ﬂag accurately, since they mostly rely on their
personal judgement. It is important to introduce more
objectivity in ﬂagging so as to improve the quality of
ﬂags.

“It is easy to understand
if that person is literate.
A primary person might
not understand that but
a highschool student
might partially
understand it and
maybe a university
student will fully
understand it.”
Female, 23yrs, Laikipia

"It's simple though at
times I read the article
and come to the options
but I get stuck on where
to place it. I have the
opinion in my mind but I
do not know what to call
it. Like I would read
something on Covid but I
do not know if it's
manipulation or spread
of fear."
Female, 30yrs, Kiambu

Busara Center For Behavioral Economics | 2021

70

PesaCheck recommends an improvement on the platform
design to improve the quality of ﬂags.

Most of PesaCheck’s recommendations were geared towards improving the platform
design, with a view to making it possible for fact-checks to be conducted on claims
associated with individual ﬂags as registered by users.

1. Consider adding the following ﬁelds to the ﬂagging platform, to enable efﬁcient

fact-checking of claims associated with individual ﬂags:
a. A text ﬁeld per ﬂag that requires users to specify which item of website content that

they would like to ﬂag.

b. A text ﬁeld per ﬂag that requires users to specify exactly why they are ﬂagging the

speciﬁc item of website content that they would like to ﬂag.

Busara Center For Behavioral Economics | 2021

71

User Motivations and
Perceptions of HIP

This section details what
motivates a user to keep ﬂagging
content online, what they hope to
gain from ﬂagging content, and
any shortcomings they believe
crowdsourcing could have.

A majority of the participants have had misinformation
shared with them.
Data:
■ All of the respondents understood the term

“misinformation” but only a few of them understood
“disinformation”. Users mostly received misinformation
by word of mouth from peers, as well as through their
social media platforms (whatsapp and facebook)
where misinformation is shared.

■ Some respondents seek to verify the information

before sharing, mostly by researching via the internet
to verify the validity of the news or conﬁrming from
their peers.

Analysis & Implication: Users need to be educated about
disinformation so that they can be able to identify and ﬂag
it as well.

“Through social media
handles, I got it through
Whatsapp and then I was
later told it is fake, the
sharing of promotions to
ﬁve Whatsapp groups.”
Female, 34yrs, Kajiado

“Any information that is
not true but has been
shared and there is no
reliable source for it.”
Female, 30yrs, Kiambu

“I read the article
and it was not true
since it was
information from no
reliable source. So I
told the person who
send it to me that
those are people
who are spreading
fear.”
Female, 30yrs,
Kiambu

Busara Center For Behavioral Economics | 2021

73

Many respondents had never reported misinformation
before HIP, despite being inclined to do so.
Data:
■ Many respondents believe that ﬂagging

misinformation is important so as to stop the spread of
false news and rumors that might be harmful or
deceptive to the public. However, not all of them had
ﬂagged misinformation prior to our introduction.

■ Some participants had never reported misinformation

because they were unaware of the appropriate
channels to report the false information they came
across. Some also feared that there might be
consequences to reporting.

■ The study ﬁndings show that some respondents

doubted if proper actions or measures would be taken
to curb the spread of the news if they reported it.

“I was not sure anything
would be done about it and
it was not the ﬁrst time
seeing it so I just ignored it.”
Female, 23yrs, Kiambu

"I used it because it was
the only way available for
reporting.”
Male, 23yrs, Nairobi.

“Sometimes you do
not know what you
are supposed to do
or which bodies to
report to and also
fear. You might
report something
and someone comes
and bullies you.”
Female, 23yrs,
Laikipia

Busara Center For Behavioral Economics | 2021

74

Many respondents had never reported misinformation
before HIP, despite being inclined to do so.
Data:

■ For participants who reported the misinformation, some of them used the report options on the social

media platform to ﬂag the users.

■ Most participants indicated that they used these methods primarily because it was the only one they

were familiar with to report.

Analysis & Implication:

Tools like HIP are not widely known. Therefore, while people have thought about reporting misinformation,
they often are not aware of the avenues towards doing this. Stakeholders should not only create some
awareness about the tool, but ensure user behaviors can sync naturally with tool use (i.e., mobile access).
Stakeholders could also leverage the fact that people are likely to recommend the tool to their social
networks, as a way of spreading information about available tools.

Busara Center For Behavioral Economics | 2021

75

In addition to ﬂagging misinformation, being able to share
worthwhile content is considered one of HIP’s value add.
Data:
■ A majority of the respondents use the HIP tool because
they want to stop the spread of misinformation and
promote healthy internet usage. The major beneﬁt of
the tool is that they can share good content that others
can beneﬁt from.

"You get a chance to push
not only bad but good
content from the browser to
that application."
Male, 22yrs, Machakos

■ Other beneﬁts include gaining knowledge, the tool is
readily available (easy to ﬁnd), it's easy to use and
doesn't take a lot of time to use.

Analysis & Implication: Having the option to ﬂag
worthwhile content is deﬁnitely a value add but because it
is highly preferred, it can reduce the amount of
misinformation that is ﬂagged, which is actually the main
objective of the HIP tool.

“It creates awareness. It
gives you knowledge
through the feedbacks
given. It can also give you
editing skills with the
articles they provide.”
Male, 28yrs, Nairobi

"To reduce the rate
of ignorance
amongst us.
Ensuring that there
is the right
information at the
ﬁrst instance is very
important.”
Female, 31, Kiambu

Busara Center For Behavioral Economics | 2021

76

Receiving an update on the actions taken by the provider
and a monetary incentive could increase usage of HIP.
Data:
■ Some people believed that their ﬂags, not through HIP
but through social media, were effective because they
saw actions taken, such as suspension or blocking of
the users account. However, some other participants
felt that their ﬂags were not effective as they did not
receive any feedback from the provider.

“When a person reports,
action should be taken and
feedback given.”
Male, 23yrs, Siaya

■ Some participants cited how adding incentives will
serve as a motivator to ﬂag users spreading false
news through HIP or any other platform. For a few
others, while an incentive is an advantage, they see
ﬂagging as a prosocial responsibility and a personal
interest to help.

“No. Availability of
incentive will just be an
added advantage but I
will still report even
without incentive.”
Male, 22yrs, Machakos

“Yes. Sometimes we
don’t pay much
attention to online
misinformation but
when an incentive is
included, sometimes
you will just go on
social media to ﬁnd
information that you
can report.”
Male, 23yrs, Kajiado

Busara Center For Behavioral Economics | 2021

77

Receiving an update on the actions taken by the provider
and a monetary incentive could increase usage of HIP.
Data:
■ Most participants who would like incentives expressed

their preference for ﬁnancial incentives, with an
average payment of 100 - 300 Kenya shillings per ﬂag,
that is, 5-10k per month.

■ Only a few people expressed preference for non-
ﬁnancial incentives, such as recognition and a
certiﬁcate of participation.

Analysis & Implication: Generally, most people will
continue to ﬂag, even without an incentive. However,
providing non ﬁnancial incentives would be a great way to
encourage HIP usage. This can be through recognizing
people who accurately ﬂag information, or providing
feedback on how their work has improved the internet.

“Monetary, once a week
or based on articles you
ﬂag.”
Female, 22yrs, Kajiado

“With comments
like thank you and
also giving a token
of appreciation.”
Female, 26yrs,
Kiambu

“Pay me with money and
give me a number of
articles that you would
like me to ﬂag. KES 1,000
for 5 ﬂags.”
Female, 34yrs, Kiambu

Busara Center For Behavioral Economics | 2021

78

There is a risk to reporting misinformation, but receiving
feedback can keep ﬂaggers motivated to keep ﬂagging.

Anonymity
Although most people trust that
HIP is anonymous (due to the use
of unique IDs, no public identifying
information required and their trust
in the provider), a few respondents
are not completely sure because
they cannot verify the truth of the
matter.

Conﬁdentiality
Some people are either not sure
or are not convinced that the
providers do not have access to
their personal digital or mobile
device. Though some people are
convinced.

"I don’t know because you can see the
address of my device (i.e., IP address). I
believe there is a way that one can see
it." Female, 22yrs, Kajiado

Cyber Bullying
Some respondents expressed
their fear of receiving threats
from people, trolls online and
being cyber bullied, which
might lead to physical harm.

Busara Center For Behavioral Economics | 2021

79

There is a risk to reporting misinformation, but receiving
feedback can keep ﬂaggers motivated to keep ﬂagging.
Data:
■ Whereas a few people did not appear to be worried

about the risks involved, many participants stated that
the risks make them worry, self conscious and less
likely to report because of fear of being attacked,
bullied or having problems with other people.

■ The respondents suggested that in order to keep

people ﬂagging despite the risks, platform providers
should provide timely feedback to the ﬂaggers to
encourage them to report.

Analysis & Implication: Emphasise the anonymity aspect
of the tool to boost the conﬁdence of users and to enable
them to keep ﬂagging. Platforms like HIP should also
provide timely feedback to users via a timeframe for all the
actions that need to be taken should be strictly adhered to.
Busara Center For Behavioral Economics | 2021

“You may become a target
due to reporting through
cyber bullying and people
may end up causing harm
to you physically if they
know who you are.”
Male, 22yrs, Nairobi.

“I think they give me
more courage to do so.
There is still need to
educate the population
about having the right
information.”
Female, 31yrs, Kiambu

“If nothing is being
done every time I
report, then that will
not motivate me at
all to report again.
Increasing
conﬁdentially for the
people doing the
reporting.”
Female, 23yrs,
Kiambu

80

Guaranteed anonymity and tagging worthwhile content
also reduces the risk attached to ﬂagging misinformation.
Data:
■ A majority of people believe there is especially a risk in
reporting misinformation for sensitive topics related to
political or tribal issues, as well as reporting inﬂuential
people or celebrities since they believe these people
will be able to ﬁnd the them.

“Yes. The way I view a
particular information
that might not be the
view of the one who
was sending the
information. So if I ﬂag
such it might affect
their work so that's a
risk.”
Female, 28yrs,
Machakos

“Yes, politics but as
long as you are
anonymous there will
not be problems or
risk but if you are not
then there can be a
problem.”
Male, 23yrs,
Kirinyaga

■ One person only tagged worthwhile content since they
believed it would not bring them any harm, and one
believed it's their opinion so there is no risk involved.

■ Some people feel that it is a risk to report people if

there is a possibility that the information could actually
not be misinformation, since this puts their jobs or work
or platforms at risk.

Busara Center For Behavioral Economics | 2021

81

Guaranteed anonymity and tagging worthwhile content
also reduces the risk attached to ﬂagging misinformation.
Data:
■ A few of those who didn't think there was a risk

believe that the anonymity element protects them.

Analysis & Implication: To bring in some objectivity, users
need to be educated on effective ways of identifying
misinformation so that they do not feel that they are risking
other people’s careers by ﬂagging subjectively.

Additionally, trust needs to be instilled in users so that they
can feel safe about ﬂagging controversial issues. Again,
providing timely feedback can boost their conﬁdence.

“Yes I believe there are risk if I
report a manipulative message
going round about political leaders
and the information being spread
is not true and I report that it
would be risky for my safety
compared to when I report
manipulation about Covid 19
vaccine.”
Female, 30 yrs, Kiambu

Busara Center For Behavioral Economics | 2021

82

Owing to the beneﬁts of the HIP tool, users are likely to
recommend it to their network.
Data:
■ Most people absolutely plan on using the HIP tool

again, especially if they can get compensation for it.
On a scale of 1 to 5, 21% rate themselves at 4 for the
likelihood of continuing to use the HIP tool, while 52%
rate themselves at 5.

■ Most people are likely to recommend the tool to people

in their network.

Analysis & Implication: Misinformation platforms can
leverage on people’s tendency to recommend products or
services to their social network. During the education or
awareness activities, this element can be incorporated into
the content.

“Based on time and
availability of internet, i
will continue using it.”
Female, 22yrs, Kajiado

"I will use it but it will
depend on whether
action is taken on the
ﬂagged content. It I will
be able to help someone
else then I will use it."
Female, 23yrs, Kiambu

"So that we can
have a large number
of people out there
ﬁghting against the
lies and security.
Secondly, I also want
my other friends to
gain because it is a
nice tool."
Female, 23yrs,
Turkana

Busara Center For Behavioral Economics | 2021

83

Recommendations
from the Full Study

A summary of recommendations for
improvements to the HIP platform.

In conclusion, volunteer-based crowdsourcing can be a
useful addition to the current misinformation ecosystem.

Throughout the report, we highlight different ways in which volunteer-based
crowdsourcing can be a value add to the existing misinformation ecosystem.

■ There is an existing culture of volunteering amongst many populations as well as a sense of
pro-social responsibility which organizations can leverage on when creating awareness for
misinformation platforms.
□ We found that despite the risk people attached to ﬂagging political content, users still ﬂagged such

content, owing to their sense of responsibility.

□ Even without an incentive, many users will continue to ﬂag misinformation, which conﬁrms that such

crowdsourcing platforms have an opportunity to leverage on people’s pro-social responsibility.

■ Crowdsourcing platforms are preferable to people because of the highlighted HIP advantages.
□ Some people were aware of other ways of ﬂagging misinformation, but preferred HIP once they were

introduced to it.

□ The study found that HIP is appropriate, easy to use, and can change the quality of content online, which

contributed to the reasons people used it.

□ Users also liked that the time needed to report misinformation using HIP was minimal.

Busara Center For Behavioral Economics | 2021

85

In conclusion, volunteer-based crowdsourcing can be a
useful addition to the current misinformation ecosystem.

Throughout the report, we highlight different ways in which volunteer-based
crowdsourcing can be a value add to the existing misinformation ecosystem.

■ The HIP tool and other crowdsourcing platforms can beneﬁt from social networks because it

can be simple to refer or introduce others in your network to the crowdsourcing tool.
□ All the respondents agreed that information needs to be veriﬁed ﬁrst before sharing. Most of them do this by

consulting with their social network (i.e., family, relatives and/or friends).

□ Users pointed out that the process of downloading and getting set up with HIP is easy and they did not
need any help in ﬂagging misinformation using it. Most of the users therefore plan on recommending the
tool to other people.

■ There are however some ways in which volunteer based crowdsourcing platforms can be

improved so as to maximize their value add. The following slides have our recommendations
on how this can be done.

Busara Center For Behavioral Economics | 2021

86

User-Driven Recommendations on Improving User
Engagement

Quality

Usage

Salience

To improve the quality of ﬂags:
Have more ﬂagging options
Simplify the ﬂagging deﬁnitions
Provide a section for putting
images
Worthwhile content should only
have 1 rating

To increase usage:
Have a version for the phone
Improve the tool’s responsiveness
Provide an incentive for active
users
Enable people to ﬂag social media
Be able to see other worthwhile
content people have ﬂagged
Translate to other languages

To increase salience of the tool:
Have prompts on the icon or
reminders
Make the icon bigger, so that it can
be salient to the users

Busara Center For Behavioral Economics | 2021

87

Our Recommendations on Improving User Engagement

Anonymity

Feedback

Access

Reinforce that the tool is
anonymous:
Remind and reinforce the reality that
using HIP can protect anonymity.
Users said they trusted the plugin
because of Busara, but not because
of HIP itself. Show the steps HIP
takes to preserve user anonymity (i.e.,
the technology used to how one
manages the reports).

Increase feedback mechanisms:
Provide a system in which users can
understand, whether on an
aggregate level or individual level,
on how feedback is being actioned.
Not only does this increase salience
of the tool, but it proves that user
behaviors make a difference. This
can be an opt-in service as this
recommendation conﬂicts with the
next on anonymity.

Enable mobile access:
Users in our qualitative follow-up
believed that having phone access
would enable them to more frequently
access the HIP plugin because this is
where they more frequently
engagement with online content,
especially via social media. Moreover,
stakeholders should create awareness
of more tools like HIP so the public can
utilise them.

Busara Center For Behavioral Economics | 2021

88

Our Recommendations on Improving User Accuracy

Remove Worthwhile

Add a Field

Create Training

Remove positive ﬂag to orient
preferred user behaviors:
Worthwhile ﬂags were
overwhelmingly used. This enables
users to feel like they are actively
using the plugin and deters the
pressure of reporting misinformation.
Alternatively, make Worthwhile one
ﬂag without the severity scale.

Create additional ﬁeld to enable
accurate identiﬁcation of
misinformation:
Make users identify which lines or
tracts of text are considered to be
“misinformation”. Failing to do this will
result in fact-checkers dismissing
most of the cases since users tend to
ﬂag entire websites, which make
identifying misinformation impossible.

Create a pre-onboarding training on
misinformation:
Users will want to know how to
identify misinformation. Our users felt
uncomfortable reporting
misinformation because they 1)
weren’t sure it was misinformation;
and 2) didn't want to harm anyone in
case they were wrong.

Busara Center For Behavioral Economics | 2021

89

Areas for Further Analysis

Clarifying Misinformation
■ It is clear from our experiment that
users are uncomfortable with
identifying misinformation, driven by
self-doubt, uncertainty, risk and a
proclivity towards ﬂagging the positive
elements of the internet.

■ Given that misinformation is

individualized towards one’s echo
chamber, what are ways to train users
on identifying misinformation in an
objective manner?

1

2

In the age of misinformation, how have other
organizations approached how to objectively train
others on identifying misinformation despite the
inﬂuence of echo chambers?

How can HIP use the essentials of this ﬁnding to
train volunteers on identifying misinformation?

Busara Center For Behavioral Economics | 2019

90

Areas for Further Analysis

1

2

Feedback Mechanisms
■ PesaCheck’s current system involves a

user ﬂagging content using the
Whatsapp platform, their team
reviewing the content, and then
providing feedback to the user in the
Whatsapp group within a 24 hour
window.

■ However, the effectiveness of this
feedback system hasn’t been
researched. This is also a gap in the
literature. The mentioned research
questions can be one way of ﬁlling this
gap, and a qualitative approach can
be used for the study.

What constitutes a timely, effective provision of
feedback to users in order to sustain their HIP
usage?

What are the best ways or methods to provide
feedback to users?

Busara Center For Behavioral Economics | 2019

91

Areas for Further Analysis

Risk and Willingness to Report
■ The study ﬁndings show that despite
users’ intent to stop the spread of
misinformation, many use the tool to
ﬂag Worthwhile content. They also
provide more information on a
Worthwhile ﬂag as opposed to a
harmful ﬂag.

■ We hypothesize that this is because of
the risk people attach to ﬂagging
harmful content. It would be useful to
further explore this through mixed
methods research on risk preferences.

1

2

How do perceptions of risk emerge when it comes
to reporting report harmful content, and what are
patterns and trends according to website type (i.e.,
political vs. non-political)?

What tools and/or framings can be used to
meaningfully address perceptions of risk on the
internet?

Busara Center For Behavioral Economics | 2019

92

Contact us for more information

acceleratorlab.ke@undp.org

| www.ke.undp.org

contact@busaracenter.org

|

www.busaracenter.org

94



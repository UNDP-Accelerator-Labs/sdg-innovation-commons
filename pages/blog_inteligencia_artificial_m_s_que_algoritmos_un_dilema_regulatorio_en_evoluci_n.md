# Inteligencia artificial, más que algoritmos: un dilema regulatorio en evolución

[[type:blog]]

[[source:https://www.undp.org/es/argentina/blog/inteligencia-artificial-mas-que-algoritmos-un-dilema-regulatorio-en-evolucion]]

[Original article published here](https://www.undp.org/es/argentina/blog/inteligencia-artificial-mas-que-algoritmos-un-dilema-regulatorio-en-evolucion)


[[year:2024]]

[[date:4 DE JUNIO DE 2024]]

[[continent:South America]]

[[country:Argentina]]



Home

Argentina

Blog

Inteligencia Artificial, Más Que Algoritmos: Un Dilema Regulatorio En Evolución

Inteligencia artificial, más que algoritmos: un dilema regulatorio en evolución Muchas son las alternativas para regular el desarrollo y uso de la inteligencia artificial. Escribimos este blog para compartir nuestros hallazgos acerca de las normativas que buscan contribuir a mitigar los riesgos y potenciar los beneficios de esta tecnología.
4 de Junio de 2024

PNUD Argentina

Escrito por

Micaela Zapata

Consultora en Laboratorio de Aceleración de PNUD Argentina

Lorena Moscovich

Jefa de Experimentación. Laboratorio de Aceleración de PNUD Argentina/ Head of Experimentation UNDP Argentina Accelerator Lab

María Verónica Moreno

Jefa de Mapeo de Soluciones. Laboratorio de Aceleración de PNUD Argentina/ Head of Solutions Mapping UNDP Argentina Accelerator Lab

María Eugenia López

Jefa de Exploración del Laboratorio de Aceleración de PNUD Argentina

La inteligencia artificial (IA) llegó para quedarse. Claro que no es totalmente nueva, ya es parte de nuestra vida cotidiana, está relacionada con el desarrollo de software y el uso de datos, muchos —pero muchos— datos. Pero también tiene innumerables implicancias que todavía desconocemos. De ahí el desafío de elegir entre las diversas alternativas para regular el desarrollo y uso de la IA, aprovechar su potencial y prevenir sus riesgos. En el Co_Lab, el Laboratorio de Aceleración de PNUD en la Argentina, pensamos que el primer paso en este camino es conocer aquellas políticas y normativas que, de manera directa o indirecta, apunten en esa dirección. Por esta razón, escribimos este blog para contarte qué encontramos y para invitarte a que nos cuentes qué otras regulaciones sumarías para avanzar hacia nuestros objetivos. Principios y recomendaciones. Primero que nada, existen guías y declaraciones con recomendaciones y principios a seguir para el uso y desarrollo de una IA segura, fiable, ética y al servicio de las personas. Algunos ejemplos son los principios de la OCDE(link is external), los de la UNESCO(link is external), o la Hoja de Ruta para la Cooperación Digital de la ONU(link is external), el reporte de su órgano asesor(link is external) y la reciente resolución de la Asamblea General(link is external).Los esfuerzos vienen también desde gobiernos, la academia, la sociedad civil y el sector privado. Una de las iniciativas precursoras fue la compilada en los principios de la Conferencia de Asilomar (2017)(link is external) del Future of Life Institute. Esta organización es la misma que más adelante, en 2023, difundió la carta abierta(link is external) que llamaba la atención sobre los riesgos de todo lo que desconocemos sobre la IA y recomendaba frenar su desarrollo al menos por seis meses. Desde nuestra región, se sumaron advertencias sobre la importancia de respetar los derechos de las personas y de evitar sesgos propios del origen de los datos. Los esfuerzos deberían estar dirigidos a construir herramientas de IA alineadas a los derechos humanos, poniendo en valor el “acervo cultural latinoamericano” y la soberanía regulatoria de los países de la región, como se destaca en la Declaración de Montevideo(link is external).Todos estos documentos internacionales mantienen áreas de contacto(link is external), incluso, de solapamiento. Por ejemplo, entre los principios que son comunes se encuentran los de responsabilidad y rendición de cuentas para una efectiva supervisión y evaluación de los modelos de IA, el de supervisión humana, los de transparencia y explicabilidad para evitar que los sistemas de IA sean “cajas negras”, los de equidad y crecimiento inclusivo y sostenible, así como seguridad, y protección a la privacidad y datos personales.Modelos de regulaciónComo estamos viendo, hay más dudas que certezas con relación a las implicancias que trae la IA y sobre cómo configurar los marcos normativos para regularlas. Una primera pregunta(link is external) es: ¿se requiere una ley general para regular todo lo referido a la IA, o más bien leyes específicas según el sector en que se aplique la tecnología? La primera opción puede facilitar un tratamiento homogéneo y cohesivo de los principios con los que se quiera gobernar el desarrollo de la IA en un país. Al mismo tiempo, puede aportar una visión integral de los riesgos y beneficios que presenta esta tecnología. Un ejemplo de este enfoque es la propuesta de ley sobre IA de la Unión Europea (UE)(link is external), que se basa en la definición de riesgos potenciales para establecer normas transversales para el desarrollo, uso y comercialización de IA.Por otro lado, una mirada centrada en los efectos específicos de la IA en cada sector (por ej. salud, trabajo o seguridad) puede ayudar a un abordaje especializado sobre riesgos y beneficios. Asimismo, se facilita la integración sectorial de la IA, aprovechando la institucionalidad de cada área para regular y monitorear. La Orden Ejecutiva sobre inteligencia artificial de Estados Unidos (EE.UU) tiene elementos cercanos a esta línea. De acuerdo con la competencia de cada ente gubernamental, la Orden les asigna tareas específicas —a cumplir también en plazos específicos— en lo referido a la creación de directrices y estándares para el desarrollo e implementación responsable de la IA según su área de actividad. Esta normativa también pone la lupa sobre el monitoreo de grandes modelos de IA y obliga a las compañías e individuos que los desarrollan a reportar sus actividades a las agencias nacionales correspondientes.La experiencia argentinaPartiendo de principios internacionales como los de UNESCO y OCDE, en el país hubo esfuerzos para discutir y avanzar en la regulación de la IA. En este aspecto, cabe ser destacado el antecedente del Plan Nacional de Inteligencia Artificial de 2019. Otras iniciativas se han orientado a establecer instancias institucionales de trabajo y promoción de la IA en el país, como la coordinación del gobierno nacional y su vinculación con universidades, empresas y gremios. Sobre la coordinación nacional, también tenemos la creación de una mesa interministerial para llevar adelante un abordaje multisectorial al desarrollo ético y sostenible de la IA en el país. Los esfuerzos nacionales también han incluido el fomento a la creación de espacios que ayuden al desarrollo de IA en idioma español y la publicación de recomendaciones para llevar adelante proyectos de innovación pública basados en IA.

Línea de tiempo de la experiencia argentina. PNUD Argentina
En general, estos documentos tienen origen en la esfera ejecutiva del gobierno y se publicaron en momentos de cambios de gestión, lo que llama la atención sobre los momentos políticos para el desarrollo de marcos normativos sobre IA y los desafíos que presentan los cambios de gobierno(link is external).El archipiélago normativoLas iniciativas nacionales mencionadas se complementan con leyes y normativas dispersas que, aunque son de otros campos —no específicamente IA —, ofrecen orientaciones y directrices sobre cómo resolver situaciones vinculadas a esta tecnología. Por ejemplo, la Ley de Protección de los Datos Personales (Ley 25.326) es una normativa fundamental para la gestión de los datos; o bien, la Ley de Propiedad Intelectual (Ley 11.723) es marco de referencia para interrogantes sobre IA y su relación con derechos de propiedad intelectual. Aunque no existe un vacío legal, la realidad es que aún no se ha sancionado una ley específica sobre IA.Estos hallazgos iniciales sobre políticas y regulaciones orientadas a mitigar los riesgos y potenciar los beneficios de la IA demuestra que el panorama es variado. Algunas políticas, resoluciones y normas se refieren específicamente a la IA, mientras que otras abordan algunos de sus aspectos. También se observa que las guías y recomendaciones internacionales han tenido un carácter performativo en las iniciativas nacionales, pues las legislaciones o resoluciones más recientes, han tendido a alinearse con estas.Se hace evidente que el proceso de regulación de la IA presenta interrogantes que requieren de un debate plural y esfuerzos colaborativos. ¿Deberían promulgarse nuevas leyes relacionadas con la IA? ¿Cómo debería gestionarse el uso de la IA en ámbitos específicos? ¿Qué ajustes son necesarios en las regulaciones existentes? ¿Cómo construir regulaciones en IA que responda a las necesidades y desafíos propios a nuestro país y región(link is external)? ¿Cómo distribuir y atribuir responsabilidades en la construir de una IA ética? Todas son preguntas que quedan abiertas a nuestra atención y acción colectiva.El Co_Lab relevó políticas, normativas y leyes, nacionales e internacionales (a las cuales Argentina ha adherido) con potencial alcance directo, o indirecto, sobre aspectos vinculados a la IA. Este relevamiento se alimentó de bibliografía especializada, de los datos del Ministerio de Justicia de la Nación y el aporte de especialistas. Accedé a este relevamiento aquí (link is external)y contanos qué otras normas agregarías. Este es un ejercicio colectivo y queremos invitarte a que nos ayudes a completar y expandir estos hallazgos iniciales. *Agradecemos la colaboración y orientación de Natalia Zuazo en el proceso de curaduría de regulaciones para este blog. Agradecemos también el apoyo en la investigación bibliográfica de Milagros Crispillo, pasante de Exploración del Co_Lab.


